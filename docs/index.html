<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!--
  <script src="./resources/jsapi" type="text/javascript"></script>
  <script type="text/javascript" async>google.load("jquery", "1.3.2");</script>
 -->
    <style type="text/css">
        @font-face {
            font-family: 'Avenir Book';
            src: url("./fonts/Avenir_Book.ttf"); /* File to be stored at your site */
        }
    body {
    font-family: "Avenir Book", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:14px;
    margin-left: auto;
    margin-right: auto;
    width: 900px;
  }
  h1 {
    font-weight:300;
  }
  h2 {
    font-weight:300;
  }

  p {
    font-weight:300;
    line-height: 1.4;
  }

  code {
    font-size: 0.8rem;
    margin: 0 0.2rem;
    padding: 0.5rem 0.8rem;
    white-space: nowrap;
    background: #efefef;
    border: 1px solid #d3d3d3;
    color: #000000;
    border-radius: 3px;
  }

  pre > code {
    display: block;
    white-space: pre;
    line-height: 1.5;
    padding: 0;
    margin: 0;
  }

  pre.prettyprint > code {
    border: none;
  }


  .container {
        display: flex;
        align-items: center;
        justify-content: center
  }
  .image {
        flex-basis: 40%
  }
  .text {
        padding-left: 20px;
        padding-right: 20px;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 0px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;

  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
</style>
	<title>Unsupervised Domain Adaptation via Structurally Regularized Deep Clustering</title>
</head>

<body>
<br>
<span style="font-size:36px">
    <div style="text-align: center;">
        Unsupervised Domain Adaptation via Structurally Regularized Deep Clustering
    </div>
</span>
<br>
<br>
<br>
<table align="center" width="700px">
    <tr>
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://huitangtang.github.io/">Hui Tang</a><sup>1</sup></span>
            </div>
        </td>
      
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:16px"><a href="https://scholar.google.com/citations?user=pbNCoTwAAAAJ">Ke Chen</a><sup>1</sup></span>
            </div>
        </td>
        
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:16px">
                    <a href="http://kuijia.site/">Kui Jia</a>
<!--                    <sup><img class="round" style="width:20px" src="./resources/corresponding_fig.png">3</sup>-->
                    <sup>&#9993, 1</sup>
                </span>
            </div>
        </td>
    </tr>
</table>

<br>
	
<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px">South China University of Technology<sup>1</sup></span>
            </center>
        </td>
    </tr>
    </tbody>
</table>


<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="300px">
            <center>
                <span style="font-size:16px"><sup>&#9993</sup>Corresponding author</span>
            </center>
        </td>
    </tr>
    </tbody>
</table>

<table align="center" width="700px">
    <tbody>
    <tr>
        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Code
                    <a href="https://github.com/Gorilla-Lab-SCUT/SRDC-CVPR2020">[GitHub]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <div style="text-align: center;">
                <span style="font-size:20px">
                    Paper
                    <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Tang_Unsupervised_Domain_Adaptation_via_Structurally_Regularized_Deep_Clustering_CVPR_2020_paper.pdf">[CVF]</a>
                </span>
            </div>
        </td>

        <td align="center" width="200px">
            <center>
                <span style="font-size:20px">
                    Cite <a href="resources/cite.txt">[BibTeX]</a>
                </span>
            </center>
        </td>
    </tr>
    </tbody>
</table>
<br>
<hr>

<div style="text-align: center;">
    <h2>Teaser</h2>
</div>

<p style="text-align:justify; text-justify:inter-ideograph;">
<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/SRDC.png" width="900px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		To address a potential issue of damaging the intrinsic data discrimination by explicitly learning domain-aligned features, 
		we propose a source-regularized, deep discriminative clustering method in order to directly uncover the intrinsic discrimination among target data, 
		termed as Structurally Regularized Deep Clustering (SRDC). 
		In SRDC, we also design useful ingredients to enhance target discrimination with clustering of intermediate network features, 
		and to enhance structural regularization with soft selection of less divergent source examples.
            </p>
        </td>
    </tr>
</table>


<br>
<hr>
<div style="text-align: center;">
    <h2>Abstract</h2>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Unsupervised domain adaptation (UDA) is to make predictions for unlabeled data on a target domain, 
		given labeled data on a source domain whose distribution shifts from the target one. 
		Mainstream UDA methods learn aligned features between the two domains, 
		such that a classifier trained on the source features can be readily applied to the target ones. 
		However, such a transferring strategy has a potential risk of damaging the intrinsic discrimination of target data. 
		To alleviate this risk, we are motivated by the assumption of structural domain similarity, 
		and propose to directly uncover the intrinsic target discrimination via discriminative clustering of target data. 
		We constrain the clustering solutions using structural source regularization that hinges on our assumed structural domain similarity. 
		Technically, we use a flexible framework of deep network based discriminative clustering 
		that minimizes the KL divergence between predictive label distribution of the network and an introduced auxiliary one; 
		replacing the auxiliary distribution with that formed by ground-truth labels of source data 
		implements the structural source regularization via a simple strategy of joint network training. 
		We term our proposed method as Structurally Regularized Deep Clustering (SRDC), 
		where we also enhance target discrimination with clustering of intermediate network features, 
		and enhance structural regularization with soft selection of less divergent source examples. 
		Careful ablation studies show the efficacy of our proposed SRDC. 
		Notably, with no explicit domain alignment, SRDC outperforms all existing methods on three UDA benchmarks.
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Background & Motivation</h2>
</div>

<table>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/UDA.png" width="600px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		The success of deep learning relies on a large amount of training data. 
		However, collecting and annotating data for all domains and tasks is extremely expensive and time-consuming. 
		We can utilize data from a label-rich source domain to solve the task on a label-scarce target domain. 
		But there is a distribution discrepancy between the source and target data. 
		So the model trained on source data cannot be readily applied to target data. 
		How to address this issue? Unsupervised domain adaptation (UDA)!
            </p>
        </td>
    </tr>
    <br>
    <tr>
        <td>
            <div style="text-align: center;">
                <img src="resources/strategy.png" width="600px">
            </div>
        </td>
    </tr>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		(a) Illustration of the assumption of structural domain similarity, including two concepts: domain-wise discrimination and class-wise closeness. 
		The orange line denotes the classifier trained on the labeled source data and the green	one denotes the classifier trained on the labeled target data, i.e. the oracle target classifier. 
		(b) Illustration of damaging intrinsic structures of data discrimination on the target domain by the existing transferring strategy. 
		The dashed line denotes the source classifier adapting to the damaged discrimination of target data, which has a sub-optimal generalization. 
		(c) Illustration of our proposed uncovering strategy. Discriminative target clustering with structural source regularization uncovers intrinsic target discrimination. 
		<br>
		<br>
		Mainstream UDA methods take the transferring strategy of learning aligned features across domains, 
		which has a potential risk of damaging the intrinsic discrimination of target data, resulting in a sub-optimal generalization. 
		Based on our assumed structural domain similarity, we directly uncover the intrinsic target discrimination via discriminative clustering of target data 
		and constrain the clustering solutions using structural source regularization, leading to an adapted classifier closer to the oracle target classifier. 
            </p>
        </td>
    </tr>
</table>

<br>
<hr>
<div style="text-align: center;">
    <h2>Highlights</h2>
</div>

<div style="text-align: center;">
    <h3>Deep Discriminative Target Clustering</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		We propose to use deep discriminative target clustering in the output space and feature space at the same time. This is a new dual clustering framework. 
		The clustering algorithm obtains pseudo labels of target data to supervise the model training by minimizing an objective of two terms. 
		The first term is the KL divergence between the network prediction label distribution and the introduced auxiliary distribution; 
		the second term is a regularization of cluster size balance. 
		<br>
		<br>
		Here, category prediction probability modeling in feature space is based on Euclidean distance from instance to learnable cluster centers. 
		The clustering behavior in feature space can not only further reveal the inherent differences between target data, 
		but also act as the constraint of clustering in output space to maintain different cluster centers and avoid mode collapse.
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Structural Source Regularization</h3>
</div>
	
<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		Based on the structural similarity between the source and target domains indicated by the UDA assumption, 
		we propose the structural source regularization — replacing the auxiliary distribution with truth label distribution, 
		and using the labeled source data to train the same classifier network layers, namely joint network training. 
		<br>
		<br>
		In addition, we propose a soft selection strategy for source samples, 
		which weights the source samples according to their importance to the target domain. 
		The concept of class-wise closeness in the assumption of structural domain similarity implies that 
		different source instances may have different regularization effects; 
		accordingly, they can be weighted based on distances to corresponding target clusters. 
            </p>
        </td>
    </tr>
</table>

<div style="text-align: center;">
    <h3>Training Algorithm</h3>
</div>
	

<div style="text-align: center;">
	<img src="resources/alg.png" width="500px">
</div>


<br>
<hr>
<div style="text-align: center;">
    <h2>Experiments</h2>
</div>

<div style="text-align: center;">
    <h3>Ablation Study and Learning Analysis</h3>
</div>

<table>
    <tr>
        <td>
            <p>
                <b>
                    R1: Ablation Study
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following table, we can observe that when any one of our designed components is removed, the performance degrades, 
		verifying that (1) both feature discrimination and structural source regularization are effective for improving target clustering; 
		(2) the proposed soft source sample selection scheme leads to better regularization. 
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab1.png" width="700px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R2: Source Refinement
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, we can observe that the source images with a canonical viewpoint have the higher weights than those with top-down, bottom-up, and side viewpoints, 
		which is intuitive since all target images are shown only from a canonical viewpoint. 
		The observation affirms the rationality of our proposed soft source sample selection scheme.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/select.png" width="700px">
            </div>
	    <p style="text-align:center;">
		The images on the left are randomly sampled from the target domain Amazon and 
		those on the right are the top-ranked (the 3<sup>rd</sup> column) and bottom-ranked (the 4<sup>th</sup> column) samples from the source domain Webcam for three classes. 
		Note that the red numbers are the computed source weights. 
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R3: Comparison under Inductive UDA Setting
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		In the following table, we can see that our proposed uncovering strategy SRDC achieves closer results to Oracle Model, 
		verifying the motivation of this work and the efficacy of our proposed SRDC.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab2.png" width="600px">
            </div>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R4: Feature Visualization
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, We can qualitatively observe that compared to Source Model, 
		the target domain features can be much better discriminated by SRDC, 
		which is based on data clustering to uncover the discriminative data structures.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tsne.png" width="900px">
            </div>
	    <p style="text-align:center;">
		The t-SNE visualization of embedded features on the target domain.
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R5: Confusion Matrix
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure,  we can observe quantitative improvements from Source Model to SRDC, further confirming the advantages of SRDC.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/confusion_matrix.png" width="900px">
            </div>
	    <p style="text-align:center;">
		The confusion matrix on the target domain.
	    </p>
        </td>
    </tr>

    <tr>
        <td>
            <br>
            <p>
                <b>
                    R6: Convergence Performance
                </b>
            </p>
            <p style="text-align:justify; text-justify:inter-ideograph;">
                In the following figure, We can observe that SRDC enjoys faster and smoother convergence performance than Source Model.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/convergence.png" width="600px">
            </div>
        </td>
    </tr>
</table>


<br>
<div style="text-align: center;">
    <h3>Comparison with SOTA</h3>
</div>

<table>
    <tr>
        <td>
            <p style="text-align:justify; text-justify:inter-ideograph;">
		 Notably, with no explicit domain alignment, our proposed SRDC outperforms all existing methods on three UDA benchmark datasets.
            </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab3.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on Office-31 (ResNet-50).
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab4.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on ImageCLEF-DA (ResNet-50).
	    </p>
	    <br>
            <div style="text-align: center;">
                <img src="resources/tab5.png" width="900px">
            </div>
	    <p style="text-align:center;">
		Results (%) on Office-Home (ResNet-50).
	    </p>
        </td>
    </tr>
</table>
	
<br>
<hr>

<div style="text-align: center;">
    <h2>BibTeX</h2>
</div>
      <pre>
  	<code>
		@inproceedings{tang2020unsupervised,
		  title={Unsupervised domain adaptation via structurally regularized deep clustering},
		  author={Tang, Hui and Chen, Ke and Jia, Kui},
		  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
		  pages={8725--8735},
		  year={2020}
		}
  	</code>
      </pre>
	
<br>
<hr>

<div style="text-align: center;">
    <h2>Acknowledgements</h2>
</div>
      <p>
	      Based on a template by <a href="https://kyanchen.github.io/OvarNet/">Keyan Chen</a>.
      </p>

<br>
<br>
<br>

</body>
</html>
